"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.compile = void 0;
var smart_buffer_1 = require("smart-buffer");
var VDF = require("vdf-parser");
var CRC32 = require("crc-32");
/**
 * Compile Source Engine captions file
 * @param vdf_text Input text to compile. Must be decoded from UTF-16 before passing.
 * @returns Compiled data
 */
function compile(vdf_text) {
    var BLOCK_SIZE = 8192;
    var HEADER_SIZE = 24;
    var DIRECTORY_ENTRY_SIZE = 4 + 4 + 2 + 2; // crc + block index + offset + length
    var data = VDF.parse(vdf_text);
    var buf = new smart_buffer_1.SmartBuffer();
    var data_buf = new smart_buffer_1.SmartBuffer(); // write raw data here before appending to the main buffer for simplicity
    // we divide data into `numblocks` blocks of `blocksize` size each
    // when the next string doesn't fit into the current block,
    // finalize the current one, write to main buffer, and begin writing new one
    var block = smart_buffer_1.SmartBuffer.fromSize(BLOCK_SIZE);
    var entries = Object.entries(data.lang.Tokens);
    // order by token alphabetically
    entries = entries.sort(function (_a, _b) {
        // note: must not use String.prototype.localeCompare, it yields different results
        var a = _a[0].toLocaleLowerCase(), b = _b[0].toLocaleLowerCase();
        if (a < b)
            return -1;
        if (a > b)
            return 1;
        return 0;
    });
    // header
    buf.writeString('VCCD', 'ascii'); // magic
    // version
    buf.writeInt32LE(1);
    // numblocks
    var numBlocksPos = buf.writeOffset;
    buf.writeInt32LE(0); // write later
    // blocksize
    buf.writeInt32LE(BLOCK_SIZE);
    // directorysize = number of entries in the directory (to get size in bytes multiply with directory entry size)
    buf.writeInt32LE(entries.length);
    var DICT_PADDING = 512 - (HEADER_SIZE + entries.length * DIRECTORY_ENTRY_SIZE) % 512;
    // dataoffset = where raw data starts (after header and all directory entries)
    buf.writeInt32LE(HEADER_SIZE + entries.length * DIRECTORY_ENTRY_SIZE + DICT_PADDING);
    var directoryOffset = buf.writeOffset; // directory entries begin here
    var dataOffset = buf.writeOffset + entries.length * DIRECTORY_ENTRY_SIZE + DICT_PADDING; // raw data begins here
    if (directoryOffset !== HEADER_SIZE)
        throw new Error("Invalid header size");
    var blockNum = 0;
    for (var _i = 0, entries_1 = entries; _i < entries_1.length; _i++) {
        var _c = entries_1[_i], token = _c[0], str = _c[1];
        var len = str.length * 2 + 2; // utf16 + null terminator
        if (block.writeOffset + len >= BLOCK_SIZE) {
            // new block time
            // write old block
            {
                // pad with zeros up to BLOCK_SIZE
                var blockDataSize = block.writeOffset;
                var paddingLength = BLOCK_SIZE - blockDataSize;
                block.writeBuffer(Buffer.alloc(paddingLength, 0)); // pad with zeroes up to BLOCK_SIZE
                // append to data buffer
                var oldOffset_1 = data_buf.writeOffset;
                data_buf.writeBuffer(block.toBuffer());
                //console.log({blockDataSize, paddingLength, oldOffset, newOffset: data_buf.writeOffset, diff: data_buf.writeOffset - oldOffset})
                if (data_buf.writeOffset !== oldOffset_1 + BLOCK_SIZE)
                    throw new Error("Invalid size when appending current block to data");
            }
            // create a new block
            {
                block = smart_buffer_1.SmartBuffer.fromSize(BLOCK_SIZE);
                blockNum++;
            }
        }
        // add to buffer
        var oldOffset = block.writeOffset;
        block.writeString(str, "utf16le");
        block.writeInt16LE(0); // null terminator
        var written = block.writeOffset - oldOffset;
        if (written !== len)
            throw new Error("Written string length is different from the string length predicted earlier on...");
        // add new dictionary entry
        var crc = CRC32.bstr(token.toLocaleLowerCase()) >>> 0;
        buf.writeUInt32LE(crc);
        buf.writeUInt32LE(blockNum);
        buf.writeUInt16LE(oldOffset);
        buf.writeUInt16LE(written);
    }
    // append the last block to data
    if (block.writeOffset > 0) {
        // pad with zeros up to BLOCK_SIZE
        var blockDataSize = block.writeOffset;
        var paddingLength = BLOCK_SIZE - blockDataSize;
        block.writeBuffer(Buffer.alloc(paddingLength, 0)); // pad with zeroes up to BLOCK_SIZE
        // append to data buffer
        var oldOffset = data_buf.writeOffset;
        data_buf.writeBuffer(block.toBuffer());
        if (data_buf.writeOffset !== oldOffset + BLOCK_SIZE)
            throw new Error("Invalid size when appending last block to data");
    }
    buf.writeBuffer(Buffer.alloc(DICT_PADDING, 0)); // dictionary padding
    if (buf.writeOffset !== dataOffset)
        throw new Error("Ended up with invalid dictionary size");
    // append data buffer to main file buffer
    buf.writeBuffer(data_buf.toBuffer());
    var expectedSize = HEADER_SIZE + DIRECTORY_ENTRY_SIZE * entries.length + DICT_PADDING + BLOCK_SIZE * (blockNum + 1);
    if (buf.writeOffset !== expectedSize)
        throw new Error("Final size differs from expected size");
    buf.writeInt32LE(blockNum + 1, numBlocksPos);
    return buf.toBuffer();
}
exports.compile = compile;
